{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchText has many canonical datasets included for classification, language modelling, sequence tagging, etc. However, frequently you'll be wanting to use your own datasets. Luckily, TorchText has functions to help you to this.\n",
    "\n",
    "Recall in the first notebook number #1\n",
    "- defined the `Field`s\n",
    "- loaded the dataset\n",
    "- created the splits\n",
    "\n",
    "As a reminder, the code is shown below:\n",
    "\n",
    "```python\n",
    "TEXT = data.Field()\n",
    "LABEL = data.LabelField()\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train_data, valid_data = train_data.split()\n",
    "```\n",
    "\n",
    "**There are three data formats TorchText can read: `json`, `tsv` (tab separated values) and`csv` (comma separated values).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8169_4</td>\n",
       "      <td>0</td>\n",
       "      <td>The movie starts with a pair of campers, a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7830_10</td>\n",
       "      <td>1</td>\n",
       "      <td>In \\Die Nibelungen: Siegfried\\\", Siegfried was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3719_9</td>\n",
       "      <td>1</td>\n",
       "      <td>Just caught it at the Toronto International Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4402_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Usually I love Lesbian movies even when they a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11134_9</td>\n",
       "      <td>1</td>\n",
       "      <td>Acidic, unremitting, and beautiful, John Schle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sentiment                                             review\n",
       "0   8169_4          0  The movie starts with a pair of campers, a man...\n",
       "1  7830_10          1  In \\Die Nibelungen: Siegfried\\\", Siegfried was...\n",
       "2   3719_9          1  Just caught it at the Toronto International Fi...\n",
       "3   4402_1          0  Usually I love Lesbian movies even when they a...\n",
       "4  11134_9          1  Acidic, unremitting, and beautiful, John Schle..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/imdb_train.csv')\n",
    "df_train.head()\n",
    "\n",
    "df_test = pd.read_csv('./data/imdb_test.csv')\n",
    "df_train.head()\n",
    "\n",
    "df_val = pd.read_csv('./data/imdb_val.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 5000, 5000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_test), len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we define our fields and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy', batch_first=True)\n",
    "LABEL = data.LabelField(sequential=False, dtype = torch.float, batch_first=True,use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use a list of tuples, where each element is also a tuple. The first element of these inner tuples will become the batch object's attribute name, second element is the `Field` name.\n",
    "\n",
    "The tuples have to be in the same order that they are within the `tsv` data. Due to this, when skipping a column of data a tuple of `None`s needs to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           id              sentiment        review\n",
    "fields = [(None, None),('sentiment',LABEL),('review',TEXT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data has a header, which ours does, it must be skipped by passing `skip_header = True`. If not, TorchText will think the header is an example. By default, `skip_header` will be `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = './data',\n",
    "                                        train = 'imdb_train.csv',\n",
    "                                        validation = 'imdb_val.csv',\n",
    "                                        test = 'imdb_test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data,max_size = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 173110),\n",
       " (',', 163792),\n",
       " ('.', 140517),\n",
       " ('and', 93819),\n",
       " ('a', 93475),\n",
       " ('of', 86009),\n",
       " ('to', 80173),\n",
       " ('is', 65575),\n",
       " ('in', 52610),\n",
       " ('I', 45963)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': '1', 'review': ['So', 'fortunate', 'were', 'we', 'to', 'see', 'this', 'fantastic', 'film', 'at', 'the', 'Palm', 'Springs', 'International', 'Film', 'festival', '.', 'Upon', 'entering', 'the', 'theater', 'we', 'were', 'handed', 'a', 'small', 'opinion', 'card', 'that', 'would', 'be', 'used', 'for', 'our', 'personal', 'rating', 'of', 'the', 'film', '.', 'Looking', 'at', 'the', 'card', 'I', 'turned', 'to', 'my', 'wife', 'and', 'said', ',', '\\\\How', 'many', 'movies', 'in', 'your', 'life', 'do', 'you', 'think', 'you', 'can', 'rate', 'as', 'superb', '?', 'Only', 'about', '5', 'for', 'me.\\\\', '\"', 'But', 'then', 'watching', 'the', 'interaction', 'between', 'Peter', 'Falk', 'and', 'Paul', 'Reiser', 'while', 'viewing', 'the', 'spectacular', 'scenery', 'in', 'the', 'film', \"'s\", 'setting', 'of', 'New', 'York', 'state', ',', 'I', 'slowly', 'starting', 'bumping', 'the', 'movie', 'up', 'a', 'category', 'at', 'a', 'time', '.', 'Certainly', 'it', 'was', 'good', 'but', 'the', 'totally', 'natural', 'repoire', 'of', 'the', 'actors', 'and', 'an', 'award', 'winning', 'performance', 'by', 'a', 'man', 'who', 'will', 'unfortunately', 'probably', 'be', 'remembered', 'for', 'a', 'raincoat', 'wearing', 'detective', 'rather', 'than', 'this', 'film', ',', 'the', 'movie', 'jumped', 'to', 'the', 'excellent', 'level.<br', '/><br', '/>By', 'the', 'end', 'of', 'the', 'film', 'there', 'were', 'few', 'dry', 'eyes', 'in', 'the', 'house', 'and', 'my', 'usually', 'stoic', 'and', 'callous', 'heart', 'melted', 'just', 'like', 'the', 'Grinch', \"'s\", 'and', 'I', 'ended', 'up', 'giving', 'this', 'a', 'superb.<br', '/><br', '/>This', 'picture', 'is', 'a', 'must', 'for', 'anyone', 'who', 'has', 'parents', '.', 'No', 'violence', 'or', 'nudity', 'but', 'some', 'strong', 'language', '.', '\"']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the vocab and create the iterators.\n",
    "\n",
    "By default, the train data is shuffled each epoch, but the validation/test data is sorted. However, TorchText doesn't know what to use to sort our data and it would throw an error if we don't tell it. \n",
    "\n",
    "There are two ways to handle this, you can either tell the iterator not to sort the validation/test data by passing `sort = False`, or you can tell it how to sort the data by passing a `sort_key`. A sort key is a function that returns a key on which to sort the data on. For example, `lambda x: x.s` will sort the examples by their `s` attribute, i.e their quote. Ideally, you want to use a sort key as the `BucketIterator` will then be able to sort your examples and then minimize the amount of padding within each batch.\n",
    "\n",
    "We can then iterate over our iterator to get batches of data. Note how by default TorchText has the batch dimension second but we added `batch_first=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort_key = lambda x: x.sentiment, #sort by s attribute (sentiment)\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 4]\n",
       "\t[.sentiment]:[torch.cuda.FloatTensor of size 4 (GPU 0)]\n",
       "\t[.review]:[torch.cuda.LongTensor of size 4x172 (GPU 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.sentiment.size:\n",
      "torch.Size([4])\n",
      "batch.review:\n",
      "torch.Size([4, 416])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(\"batch.sentiment.size:\")\n",
    "    print(batch.sentiment.size())\n",
    "    print(\"batch.review:\")\n",
    "    print(batch.review.size())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
